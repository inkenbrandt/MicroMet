{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This notebook was used to compile all of the available data from the Utah Flux Network stations.  It should only need to be used once, as other notebooks are used to comile the newer data.",
   "id": "8e6cb5d9c8ae57b4"
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T20:04:24.166323Z",
     "iopub.status.busy": "2024-10-01T20:04:24.166323Z",
     "iopub.status.idle": "2024-10-01T20:04:27.390335Z",
     "shell.execute_reply": "2024-10-01T20:04:27.390335Z",
     "shell.execute_reply.started": "2024-10-01T20:04:24.166323Z"
    },
    "ExecuteTime": {
     "end_time": "2024-12-28T02:58:12.128541Z",
     "start_time": "2024-12-28T02:58:09.755762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import urllib\n",
    "import sys\n",
    "import pathlib\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.parse import quote\n",
    "from sqlalchemy import create_engine\n",
    "import configparser\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "#import pingouin as pg\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "61e3a29165852b08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T20:04:27.394344Z",
     "iopub.status.busy": "2024-10-01T20:04:27.391341Z",
     "iopub.status.idle": "2024-10-01T20:04:28.485295Z",
     "shell.execute_reply": "2024-10-01T20:04:28.485295Z",
     "shell.execute_reply.started": "2024-10-01T20:04:27.394344Z"
    },
    "ExecuteTime": {
     "end_time": "2024-12-28T02:58:19.632874Z",
     "start_time": "2024-12-28T02:58:19.154832Z"
    }
   },
   "source": [
    "sys.path.append(\"//\")\n",
    "#sys.path.append(\"../../Micromet\")\n",
    "import micromet\n",
    "from micromet import AmerifluxDataProcessor\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T02:58:26.322749Z",
     "start_time": "2024-12-28T02:58:26.266874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = configparser.ConfigParser()\n",
    "\n",
    "config.read('../../secrets/config.ini')\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import urllib.parse\n",
    "host = config['DEFAULT']['ip']\n",
    "pw = config['DEFAULT']['pw']\n",
    "user = config['DEFAULT']['login']\n",
    "\n",
    "encoded_password = urllib.parse.quote_plus(pw)\n",
    "\n",
    "def postconn_et(encoded_password, host='localhost',user='postgres',port='5432',db='groundwater', schema = 'groundwater'):\n",
    "    connection_text = \"postgresql+psycopg2://{:}:{:}@{:}:{:}/{:}?gssencmode=disable\".format(user,encoded_password,host,port,db)\n",
    "    return create_engine(connection_text, connect_args={'options': '-csearch_path={}'.format(schema)})\n",
    "\n",
    "\n",
    "engine = postconn_et(encoded_password, host=host, user=user)"
   ],
   "id": "fddcebdfd6a7b51c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "ad20f401f01ce92f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T14:09:27.572520Z",
     "iopub.status.busy": "2024-10-01T14:09:27.572520Z",
     "iopub.status.idle": "2024-10-01T14:09:27.607540Z",
     "shell.execute_reply": "2024-10-01T14:09:27.607540Z",
     "shell.execute_reply.started": "2024-10-01T14:09:27.572520Z"
    },
    "ExecuteTime": {
     "end_time": "2024-12-28T02:59:46.257678Z",
     "start_time": "2024-12-28T02:58:44.070499Z"
    }
   },
   "source": [
    "site_folders = {'US-UTD':'Dugout_Ranch',\n",
    "                'US-UTB':'BSF',\n",
    "                'US-UTJ':'Bluff',\n",
    "                'US-UTW':'Wellington',\n",
    "                'US-UTE':'Escalante',\n",
    "                'US-UTM':'Matheson',\n",
    "                'US-UTP':'Phrag',\n",
    "                'US-CdM':'Cedar_mesa',\n",
    "                'US-UTV':'Desert_View_Myton',\n",
    "                'US-UTN':'Juab'\n",
    "                }\n",
    "\n",
    "\n",
    "compdf = {}\n",
    "\n",
    "am = micromet.AmerifluxDataProcessor()\n",
    "\n",
    "for key, value in site_folders.items():\n",
    "\n",
    "    print(key)\n",
    "    raw_fold = pathlib.Path('H:/UGS_Flux/Data_Downloads/')\n",
    "    raw_data = am.raw_file_compile(raw_fold, value, search_str = \"*Flux_AmeriFluxFormat*.dat\")\n",
    "    if raw_data is not None:\n",
    "        am_data = micromet.Reformatter(raw_data, data_path=\"C:/Users/paulinkenbrandt/Documents/GitHub/MicroMet/data/extreme_values.csv\")\n",
    "        am_df = am_data.et_data\n",
    "        compdf[key] = am_df\n",
    "\n",
    "        am_df.to_csv(f\"../../station_data/{key}_HH_{am_df['TIMESTAMP_START'].values[0]:}_{am_df['TIMESTAMP_END'].values[-1]:}.csv\")\n",
    "        #am_df['stationid'] = key\n",
    "        \n",
    "        #am_df.to_sql('amfluxeddy', key, engine, if_exists='append',schema='groundwater')\n",
    "        \n",
    "cdf = pd.concat(compdf,axis=0)\n",
    "cdf.index.set_names(['stationid','datetime_start'],inplace=True)\n",
    "#cdf.rename(columns={'level_0':'stationid'},inplace=True)\n",
    "#cdf.to_parquet('../station_data/all_data.parquet')\n",
    "for col in cdf.columns:\n",
    "    cdf.rename(columns={col:col.lower()},inplace=True)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US-UTD\n",
      "US-UTB\n",
      "US-UTJ\n",
      "US-UTW\n",
      "US-UTE\n",
      "US-UTM\n",
      "Unknown header format for file: H:\\UGS_Flux\\Data_Downloads\\Matheson\\8442_Flux_AmeriFluxFormat_0.dat\n",
      "Unknown header format for file: H:\\UGS_Flux\\Data_Downloads\\Matheson\\d20211228\\8442_Flux_AmeriFluxFormat_0.dat\n",
      "Unknown header format for file: H:\\UGS_Flux\\Data_Downloads\\Matheson\\d20220215\\8442_Flux_AmeriFluxFormat_0.dat\n",
      "Unknown header format for file: H:\\UGS_Flux\\Data_Downloads\\Matheson\\d20220323\\8442_Flux_AmeriFluxFormat_0.dat\n",
      "US-UTP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:945: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:945: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:945: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US-CdM\n",
      "Unknown header format for file: H:\\UGS_Flux\\Data_Downloads\\Cedar_mesa\\e20241008\\45027_Flux_AmeriFluxFormat_6.dat\n",
      "US-UTV\n",
      "US-UTN\n",
      "Unknown header format for file: H:\\UGS_Flux\\Data_Downloads\\Juab\\20210622_farm\\8441_Flux_AmeriFluxFormat_4.dat\n",
      "Unknown header format for file: H:\\UGS_Flux\\Data_Downloads\\Juab\\combined_farm\\8441_Flux_AmeriFluxFormat_4.dat\n",
      "Unknown header format for file: H:\\UGS_Flux\\Data_Downloads\\Juab\\20210826_farmNephi\\20210826\\8441_Flux_AmeriFluxFormat_11.dat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:945: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:945: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:945: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:945: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:945: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:945: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:945: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:945: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:945: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:945: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:945: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:945: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:945: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:945: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T03:05:29.870280Z",
     "start_time": "2024-12-28T03:01:28.804960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cdf.to_sql(name = 'amfluxeddy',\n",
    "           schema='groundwater',\n",
    "           con=engine,\n",
    "           if_exists='replace',\n",
    "           chunksize=2000)"
   ],
   "id": "714ce788442a9680",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15788"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T05:01:58.442720Z",
     "start_time": "2024-12-27T05:01:58.432323Z"
    }
   },
   "cell_type": "code",
   "source": "am_df[['file_no','TIMESTAMP_START','TIMESTAMP_END']]",
   "id": "88e9186bac4325e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     file_no  TIMESTAMP_START  TIMESTAMP_END\n",
       "datetime_start                                              \n",
       "2018-08-22 10:00:00  -9999.0     201808221000   201808221030\n",
       "2018-08-22 10:30:00      8.0     201808221030   201808221100\n",
       "2018-08-22 11:00:00      8.0     201808221100   201808221130\n",
       "2018-08-22 11:30:00      8.0     201808221130   201808221200\n",
       "2018-08-22 12:00:00      8.0     201808221200   201808221230\n",
       "...                      ...              ...            ...\n",
       "2024-05-09 08:30:00      8.0     202405090830   202405090900\n",
       "2024-05-09 09:00:00      8.0     202405090900   202405090930\n",
       "2024-05-09 09:30:00      8.0     202405090930   202405091000\n",
       "2024-05-09 10:00:00      8.0     202405091000   202405091030\n",
       "2024-05-09 10:30:00      8.0     202405091030   202405091100\n",
       "\n",
       "[100178 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_no</th>\n",
       "      <th>TIMESTAMP_START</th>\n",
       "      <th>TIMESTAMP_END</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime_start</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-08-22 10:00:00</th>\n",
       "      <td>-9999.0</td>\n",
       "      <td>201808221000</td>\n",
       "      <td>201808221030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-22 10:30:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>201808221030</td>\n",
       "      <td>201808221100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-22 11:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>201808221100</td>\n",
       "      <td>201808221130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-22 11:30:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>201808221130</td>\n",
       "      <td>201808221200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-22 12:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>201808221200</td>\n",
       "      <td>201808221230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-09 08:30:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>202405090830</td>\n",
       "      <td>202405090900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-09 09:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>202405090900</td>\n",
       "      <td>202405090930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-09 09:30:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>202405090930</td>\n",
       "      <td>202405091000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-09 10:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>202405091000</td>\n",
       "      <td>202405091030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-09 10:30:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>202405091030</td>\n",
       "      <td>202405091100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100178 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T06:02:12.041319Z",
     "start_time": "2024-12-27T06:02:06.307832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def file_compile(\n",
    "    raw_fold: Path,\n",
    "    station_folder_name: Path,\n",
    "    search_str=\"*Flux_AmeriFluxFormat*.dat\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Compiles raw AmeriFlux datalogger files into a single dataframe.\n",
    "\n",
    "    :param raw_fold: Path to the root folder of raw datalogger files\n",
    "    :type raw_fold: pathlib.Path\n",
    "    :param station_folder_name: Name of the station folder containing the raw datalogger files\n",
    "    :type station_folder_name: str\n",
    "    :return: Dataframe containing compiled AmeriFlux data, or None if no valid files found\n",
    "    :rtype: pandas.DataFrame or None\n",
    "    \"\"\"\n",
    "    amflux = {}\n",
    "    station_folder = raw_fold / station_folder_name\n",
    "\n",
    "\n",
    "    # iterate through specified folder of raw datalogger files (.dat); Match to AmeriFlux datalogger files\n",
    "    for file in station_folder.rglob(search_str):\n",
    "        # get the base number of the raw ameriflux file\n",
    "        baseno = file.name.split(\".\")[0]\n",
    "\n",
    "        try:\n",
    "            file_number = int(baseno.split(\"_\")[-1])\n",
    "        except:\n",
    "            file_number = 9999\n",
    "\n",
    "        if file_number >= 0:\n",
    "            try:\n",
    "                df = pd.read_csv(file,\n",
    "                                 skiprows=[1, 2],\n",
    "                                 usecols=[0,1],\n",
    "                                 na_values=[-9999,\"NAN\",\"NaN\"])\n",
    "            except:\n",
    "                df = None\n",
    "            if df is not None:\n",
    "                #print(df.columns[0])\n",
    "                # print(file)\n",
    "                if df.columns[0] ==  \"TIMESTAMP_START\":\n",
    "                    df[\"file_no\"] = file_number\n",
    "                    df[\"baseno\"] = baseno\n",
    "                    amflux[baseno] = df\n",
    "\n",
    "    if amflux:\n",
    "        # concat dataframes that were successfully read in\n",
    "        et_data = pd.concat(amflux, axis=0).reset_index()\n",
    "        #et_data = et_data.drop(columns=[\"level_0\", \"level_1\"])\n",
    "    else:\n",
    "        et_data = None\n",
    "    return et_data\n",
    "\n",
    "date_data = {}\n",
    "for key, value in site_folders.items():\n",
    "\n",
    "    #print(key)\n",
    "    raw_fold = pathlib.Path('H:/UGS_Flux/Data_Downloads/')\n",
    "    date_data[key] = file_compile(raw_fold, value, search_str = \"*Flux_AmeriFluxFormat*.dat\")\n",
    "\n",
    "df = pd.concat(date_data,axis=0)\n",
    "dfmod = df.drop(['level_0','level_1'],axis=1).reset_index().drop(['level_1'],axis=1).rename(columns={'level_0':'stationid'})#.set_index(['stationid','file_no'])\n",
    "dfmod['TIMESTAMP_START'] = dfmod['TIMESTAMP_START'].astype('int')\n",
    "dfmod['TIMESTAMP_END'] = dfmod['TIMESTAMP_END'].astype('int')\n",
    "dfmod.sort_values(['stationid','file_no'],inplace=True)\n",
    "\n",
    "def f(x):\n",
    "    d = {}\n",
    "    d['start_min'] = x['TIMESTAMP_START'].min()\n",
    "    d['start_max'] = x['TIMESTAMP_START'].max()\n",
    "    d['end_min'] = x['TIMESTAMP_END'].min()\n",
    "    d['end_max'] = x['TIMESTAMP_END'].max()\n",
    "\n",
    "    d['file'] = x['baseno'].values[0]\n",
    "    return pd.Series(d, index=d.keys())\n",
    "\n",
    "dstats = dfmod.groupby(['stationid','file_no']).apply(f)\n"
   ],
   "id": "183103312ced13cc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulinkenbrandt\\AppData\\Local\\Temp\\1\\ipykernel_11876\\1203840080.py:79: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  dstats = dfmod.groupby(['stationid','file_no']).apply(f)\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T06:04:15.377605Z",
     "start_time": "2024-12-27T06:04:14.295211Z"
    }
   },
   "cell_type": "code",
   "source": "\n",
   "id": "192764b46d3f5910",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "51bb65809614a82c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
